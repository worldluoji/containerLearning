1. 什么是CRI?
把 kubelet 对容器的操作，统一地抽象成一个接口。
这样，kubelet 就只需要跟这个接口打交道了。
而作为具体的容器项目，比如 Docker、 rkt、runV，它们就只需要自己提供一个该接口的实现，
然后对 kubelet 暴露出 gRPC 服务即可。
这一层统一的容器操作接口，就是 CRI 了。

比如，容器项目是 Docker ，那么负责响应这个请求的就是一个叫作 dockershim 的组件。
它会把 CRI 请求里的内容拿出来，然后组装成 Docker API 请求发给 Docker Daemon。
需要注意的是，在 Kubernetes 目前的实现里，dockershim 依然是 kubelet 代码的一部分。
当然，在将来，dockershim 肯定会被从 kubelet 里移出来，甚至直接被废弃掉。

2. CRI 机制能够发挥作用的核心
CRI 机制能够发挥作用的核心, 就在于每一种容器项目现在都可以自己实现一个 CRI shim，自行对 CRI 请求进行处理。
这样，Kubernetes 就有了一个统一的容器抽象层，使得下层容器运行时可以自由地对接进入 Kubernetes 当中。

举个例子。CNCF 里的 containerd 项目，就可以提供一个典型的 CRI shim 的能力，即：将 Kubernetes 发出的 CRI 请求，
转换成对 containerd 的调用，然后创建出 runC 容器。
而 runC 项目，才是负责执行我们前面讲解过的设置容器 Namespace、Cgroups 和 chroot 等基础操作的组件。

3.CRI分为两组
第一组，是 RuntimeService。它提供的接口，主要是跟容器相关的操作。比如，创建和启动容器、删除容器、执行 exec 命令等等。
第二组，是ImageService。它提供的接口，主要是容器镜像相关的操作，比如拉取镜像、删除镜像等等

4.CRI 设计的一个重要原则，就是确保这个接口本身，只关注容器，不关注 Pod。这样做的原因：
第一，Pod 是 Kubernetes 的编排概念，而不是容器运行时的概念。
所以，我们就不能假设所有下层容器项目，都能够暴露出可以直接映射为 Pod 的 API。
第二，如果 CRI 里引入了关于 Pod 的概念，那么接下来只要 Pod API 对象的字段发生变化，那么 CRI 就很有可能需要变更。
而在 Kubernetes 开发的前期，Pod 对象的变化还是比较频繁的，但对于 CRI 这样的标准接口来说，这个变更频率就有点麻烦了。

5.在 CRI 的设计里，并没有一个直接创建 Pod 或者启动 Pod 的接口。
不过，CRI 里还是有一组叫作 RunPodSandbox 的接口的。
这个 PodSandbox，对应的并不是 Kubernetes 里的 Pod API 对象，而只是抽取了 Pod 里的一部分与容器运行时相关的字段，
比如 HostName、DnsConfig、CgroupParent 等。
所以说，PodSandbox 这个接口描述的，其实是 Kubernetes 将 Pod 这个概念映射到容器运行时层面所需要的字段，
或者说是一个 Pod 对象子集。
一个隔离的应用运行时环境叫容器，一组共同被 Pod 约束的容器就叫 Pod Sandbox。她们同生共死，共享底层资源。

6. 在具体的 CRI shim 中，这些接口（CRI Example.png）的实现是可以完全不同的。
比如，如果是 Docker 项目，dockershim 就会创建出一个名叫 foo 的 Infra 容器（pause 容器），
用来“hold”住整个 Pod 的 Network Namespace。
Kubernetes 在启动 Infra 容器之后，就可以直接调用 CNI 网络插件，为这个 Infra 容器的 Network Namespace，配置符合预期的网络栈。
(如果容器运行时是containerd, 通过crictl pod可以查看到Pod Sandbox对应的容器，包括pause容器；crictl ps则和docker ps一样)

创建 Pod 时 Kubelet 先调用 CRI 接口 RuntimeService.RunPodSandbox 来创建一个沙箱环境，
为 Pod 设置网络（例如：分配 IP）等基础运行环境。当 Pod 沙箱（Pod Sandbox）建立起来后，
Kubelet 就可以在里面创建用户容器。当到删除 Pod 时，Kubelet 会先移除 Pod Sandbox 然后再停止里面的所有容器。

Kubernetes 中所谓的 pause 容器有时候也称为 infra 容器（用C语言编写），它与用户容器捆绑运行在同一个 Pod 中，
最大的作用是维护 Pod 网络协议栈。
当然，也包括其他工作，比如清理僵尸进程：
这个“暂停”容器运行一个非常简单的进程，它不执行任何功能，一启动就永远把自己阻塞住了（见 pause() 系统调用）。
它执行另一个重要的功能——即它扮演 PID 1 的角色，并在子进程成为孤儿进程的时候通过调用 
wait() 收割这些僵尸子进程。这样我们就不用担心我们的 Pod 的 PID namespace 里会堆满僵尸进程了。
这也是为什么 Kubernetes 不随便找个容器（例如：Nginx）作为父容器，然后让用户容器加入的原因了。

如果是基于虚拟化技术的容器，比如 Kata Containers 项目，它的 CRI 实现就会直接创建出一个轻量级虚拟机来充当 Pod。

需要注意的是，在 RunPodSandbox 这个接口的实现中，你还需要调用 networkPlugin.SetUpPod(…) 来为这个 Sandbox 设置网络。
这个 SetUpPod(…) 方法，实际上就在执行 CNI 插件里的 add(…) 方法，也就是 CNI 插件为 Pod 创建网络，
并且把 Infra 容器加入到网络中的操作。

接下来，kubelet 继续调用 CreateContainer 和 StartContainer 接口来创建和启动容器 A、B。
对应到 dockershim 里，就是直接启动 A，B 两个 Docker 容器。所以最后，宿主机上会出现三个 Docker 容器组成这一个 Pod。
而如果是 Kata Containers 的话，CreateContainer 和 StartContainer 接口的实现，
就只会在前面创建的轻量级虚拟机里创建两个 A、B 容器对应的 Mount Namespace。
所以，最后在宿主机上，只会有一个叫作 foo 的轻量级虚拟机在运行。

7. Streaming API
除了上述对容器生命周期的实现之外，CRI shim 还有一个重要的工作，就是如何实现 exec、logs 等接口。
这些接口跟前面的操作有一个很大的不同，就是这些 gRPC 接口调用期间，kubelet 需要跟容器项目维护一个长连接来传输数据。
这种 API，我们就称之为 Streaming API。
参考流程图"kubctl exec streaming api.png"

对一个容器执行 kubectl exec 命令的时候，这个请求首先交给 API Server，然后 API Server 就会调用 kubelet 的 Exec API。
然后，kubelet 就会调用 CRI 的 Exec 接口，而负责响应这个接口的，自然就是具体的 CRI shim。

但在这一步，CRI shim 并不会直接去调用后端的容器项目（比如 Docker ）来进行处理，而只会返回一个 URL 给 kubelet。
这个 URL，就是该 CRI shim 对应的 Streaming Server 的地址和端口。

而 kubelet 在拿到这个 URL 之后，就会把它以 Redirect 的方式返回给 API Server。
所以这时候，API Server 就会通过重定向来向 Streaming Server 发起真正的 /exec 请求，与它建立长连接。

当然，这个 Streaming Server 本身，是需要通过使用 SIG-Node 为你维护的 Streaming API 库来实现的。
并且，Streaming Server 会在 CRI shim 启动时就一起启动。
此外，Stream Server 这一部分具体怎么实现，完全可以由 CRI shim 的维护者自行决定。
比如，对于 Docker 项目来说，dockershim 就是直接调用 Docker 的 Exec API 来作为实现的。

8. 从这些讲解中不难看出，CRI 这个接口的设计，实际上还是比较宽松的。
这就意味着，作为容器项目的维护者，我在实现 CRI 的具体接口时，往往拥有着很高的自由度，
这个自由度不仅包括了容器的生命周期管理，也包括了如何将 Pod 映射成为我自己的实现，
还包括了如何调用 CNI 插件来为 Pod 设置网络的过程。