1. Prometheus
Prometheus 项目与 Kubernetes 项目一样，也来自于 Google 的 Borg 体系，它的原型系统，叫作 BorgMon，
是一个几乎与 Borg 同时诞生的内部监控系统。

Prometheus 项目工作的核心，是使用 Pull （抓取）的方式去搜集被监控对象的 Metrics 数据（监控指标数据），
然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，
以便后续可以按照时间进行检索。

有了这套核心监控机制， Prometheus 剩下的组件就是用来配合这套机制的运行。
比如 Pushgateway，可以允许被监控对象以 Push 的方式向 Prometheus 推送 Metrics 数据。
而 Alertmanager，则可以根据 Metrics 信息灵活地设置报警。
当然， Prometheus 最受用户欢迎的功能，还是通过 Grafana 对外暴露出的、可以灵活配置的监控数据可视化界面。


2. Prometheus监控kubernates的相关metrics
第一种 Metrics，是宿主机的监控数据。这部分数据的提供，需要借助一个由 Prometheus 维护的Node Exporter 工具。
一般来说，Node Exporter 会以 DaemonSet 的方式运行在宿主机上。
其实，所谓的 Exporter，就是代替被监控对象来对 Prometheus 暴露出可以被“抓取”的 Metrics 信息的一个辅助进程。
而 Node Exporter 可以暴露给 Prometheus 采集的 Metrics 数据，
也不单单是节点的负载（Load）、CPU 、内存、磁盘以及网络这样的常规信息，它的 Metrics 指标可以说是“包罗万象”。
https://github.com/prometheus/node_exporter#enabled-by-default

第二种 Metrics，是来自于 Kubernetes 的 API Server、kubelet 等组件的 /metrics API。
除了常规的 CPU、内存的信息外，这部分信息还主要包括了各个组件的核心监控指标。
比如，对于 API Server 来说，它就会在 /metrics API 里，
暴露出各个 Controller 的工作队列（Work Queue）的长度、请求的 QPS 和延迟数据等等。
这些信息，是检查 Kubernetes 本身工作情况的主要依据。

第三种 Metrics，是 Kubernetes 相关的监控数据。
这部分数据，一般叫作 Kubernetes 核心监控数据（core metrics）。这其中包括了 Pod、Node、
容器、Service 等主要 Kubernetes 核心概念的 Metrics。
其中，容器相关的 Metrics 主要来自于 kubelet 内置的 cAdvisor 服务。
在 kubelet 启动后，cAdvisor 服务也随之启动，而它能够提供的信息，
可以细化到每一个容器的 CPU 、文件系统、内存、网络等资源的使用情况。

3. 具体的监控指标规划，业界通用的 USE 原则和 RED 原则
USE 原则指的是，按照如下三个维度来规划资源监控指标：
利用率（Utilization），资源被有效利用起来提供服务的平均时间占比；
饱和度（Saturation），资源拥挤的程度，比如工作队列的长度；
错误率（Errors），错误的数量。
而 RED 原则指的是，按照如下三个维度来规划服务监控指标：
每秒请求数量（Rate）；
每秒错误数量（Errors）；
服务响应时间（Duration）。

USE 原则主要关注的是“资源”，比如节点和容器的资源使用情况，
而 RED 原则主要关注的是“服务”，比如 kube-apiserver 或者某个应用的工作情况。
这两种指标，在 Kubernetes + Prometheus 组成的监控体系中，都是可以完全覆盖到的。