1. EndpointSlice, Kubernetes v1.21 [stable]
它为 Endpoints 提供了一种可伸缩和可拓展的替代方案。

如果使用 Endpoint API，Service 只有一个 Endpoint 资源。
这意味着它需要为 Service 的每个 Pod 都存储好 IP 地址和端口（网络端点），这需要大量的 API 资源。
另外，kube-proxy 会在每个节点上运行，并监控 Endpoint 资源的任何更新。
如果 Endpoint 资源中有一个端口发生更改，那么整个对象都会分发到 kube-proxy 的每个实例。

Endpoint API 另一个局限是，它会限制跟踪 Service 的网络端点数量。
一般存储在 etcd 中的对象默认大小限制为 1.5MB。
在某些情况下，它会将 Endpoint 资源限制为 5000 个 Pod IP。
对于大多数用户而言，这没什么关系，但是对于接近这个大小的 Service 而言，就有大问题了。

举一个简单的例子。如果一个 Service 有 5000 个 Pod，它如果有 1.5MB 的 Endpoint 资源。
当该列表中的某个网络端点发生了变化，那么就要将完整的 Endpoint 资源分发给集群中的每个节点。
在具有 3000 个节点的大型集群中，这会是个很大的问题。
每次更新将跨集群发送 4.5GB 的数据（1.5MB*3000，即 Endpoint 大小 * 节点个数），
并且每次端点更新都要发送这么多数据。想象一下，如果进行一次滚动更新，共有 5000 个 Pod 全部被替换，
那么传输的数据量将超过 22 TB。

EndpointSlice API 旨在通过类似于分片的方法来解决该问题。
我们不跟踪 Service Pod IP 的单个 Endpoint 资源，而是将它们拆分为多个较小的 EndpointSlice。
举个例子，现在有 15 个 Pod 在支持一个 Service，那么就有跟踪这些的一个 Endpoint 资源。
如果将 EndpointSlice 配置为每个EndpointSlice 存储 5 个端点，
就得到了 3 个不同的 EndpointSlice(见图endpintslice.PNG)。

默认情况下，EndpointSlice 每个存储能多达 100 个端点，
我们可以使用 kube-controller-manager 的 --max-endpoints-per-slice 标签进行配置。


2. example
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  name: example-abc
  labels:
    kubernetes.io/service-name: example
addressType: IPv4
ports:
  - name: http
    protocol: TCP
    port: 80
endpoints:
  - addresses:
      - "10.1.2.3"
    conditions:
      ready: true
    hostname: pod-1
    nodeName: node-1
    zone: us-west2-a

默认情况下，控制面创建和管理的 EndpointSlice 将包含不超过 100 个端点。 
你可以使用 kube-controller-manager 的 --max-endpoints-per-slice 标志设置此值，最大值为 1000。
当涉及如何路由内部流量时，EndpointSlice 可以充当 kube-proxy 的决策依据。 
启用该功能后，在服务的端点数量庞大时会有可观的性能提升。


3. EndpointSlice 支持三种地址类型：
IPv4
IPv6
FQDN (完全合格的域名)

4. EndpointSlice API 存储了可能对使用者有用的、有关端点的状态。 
这三个状态分别是 ready、serving 和 terminating。
1) terminating 是表示端点是否处于终止中的状况；
 
2) ready is a condition that maps to a Pod's Ready condition. 
A running Pod with the Ready condition set to True should have this EndpointSlice condition also set to true. 
For compatibility reasons, ready is NEVER true when a Pod is terminating. 
Consumers should refer to the serving condition to inspect the readiness of terminating Pods. 
The only exception to this rule is for Services with spec.publishNotReadyAddresses set to true.
Endpoints for these Services will always have the ready condition set to true

3) serving is identical to the ready condition, 
except it does not account for terminating states. 
Consumers of the EndpointSlice API should check this condition 
if they care about pod readiness while the pod is also terminating.


5. Topology information 
Each endpoint within an EndpointSlice can contain relevant topology information. 
The topology information includes the location of the endpoint and information about the corresponding Node and zone. 
These are available in the following per endpoint fields on EndpointSlices:

nodeName - The name of the Node this endpoint is on.
zone - The zone this endpoint is in.


6. EndpointSlice 提升 10 倍可伸缩性
EndpointSlice API 大大提高了网络的可伸缩性，因为现在添加或删除 Pod 时，
只需更新 1 个小的 EndpointSlice。尤其是成百上千个 Pod 支持单个 Service 时，差异将非常明显。

更重要的是，既然 Service 的所有 Pod IP 都不需要存储在单个资源中，
那么我们就不必担心 etcd 中存储对象的大小限制。
EndpointSlice 可以用于扩展到超过 10 万个网络端点的 Service。
当这些与 kube-proxy 的一些重大性能改进结合在一起后，再大规模地使用 EndpointSlice 时，
用于端点更新的数据将大大减少，kube-proxy 还可以更快更新 iptables 和 ipvs 规则。
这样，Service 现在的可伸缩性能达到以前的至少 10 倍。

7. Service Topology

服务拓扑（Service Topology）可以让一个服务基于集群的 Node 拓扑进行流量路由。 
例如，一个服务可以指定流量是被优先路由到一个和客户端在同一个 Node 或者在同一可用区域的端点。

此功能特性，尤其是 Alpha 阶段的 topologyKeys API，在 Kubernetes v1.21 版本中已被废弃。
Kubernetes v1.21 版本中，正是使用了EndpointSlice取代该特性。

例子：
一个集群中，其 Node 的标签被打为其主机名，区域名和地区名，那么就可以设置 Service 的 topologyKeys 的值定向流量。
优先选择节点本地端点，地域端点，然后是区域端点，最后才是集群范围端点的一种服务。

apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - "kubernetes.io/hostname"
    - "topology.kubernetes.io/zone"
    - "topology.kubernetes.io/region"
    - "*"

参考：https://kubernetes.io/zh/docs/concepts/services-networking/service-topology/
https://kubernetes.io/zh/docs/concepts/services-networking/topology-aware-hints/